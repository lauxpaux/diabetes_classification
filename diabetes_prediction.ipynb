{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9682ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad70b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed7f74",
   "metadata": {},
   "source": [
    "### The data columns are:\n",
    "\n",
    "1) Pregnancy\n",
    "2) Glucose\n",
    "3) Blood Pressure\n",
    "4) SkinThickness\n",
    "5) Insulin\n",
    "6) BMI\n",
    "7) DiabetesPedigreeFunction\n",
    "8) Age\n",
    "9) Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf9dd08",
   "metadata": {},
   "source": [
    "## Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca5e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f102c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "1     6  148  72  35    0  33.6  0.627  50  1\n",
       "2     1   85  66  29    0  26.6  0.351  31  0\n",
       "3     8  183  64   0    0  23.3  0.672  32  1\n",
       "4     1   89  66  23   94  28.1  0.167  21  0\n",
       "5     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "764  10  101  76  48  180  32.9  0.171  63  0\n",
       "765   2  122  70  27    0  36.8   0.34  27  0\n",
       "766   5  121  72  23  112  26.2  0.245  30  0\n",
       "767   1  126  60   0    0  30.1  0.349  47  1\n",
       "768   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb3907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['6', '148', '72', ..., '0.627', '50', '1'],\n",
       "       ['1', '85', '66', ..., '0.351', '31', '0'],\n",
       "       ['8', '183', '64', ..., '0.672', '32', '1'],\n",
       "       ...,\n",
       "       ['5', '121', '72', ..., '0.245', '30', '0'],\n",
       "       ['1', '126', '60', ..., '0.349', '47', '1'],\n",
       "       ['1', '93', '70', ..., '0.315', '23', '0']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee662c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:8]\n",
    "y = data[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4737f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434959a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled:\n",
      " [[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
      "   1.4259954 ]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
      "  -0.19067191]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
      "  -0.10558415]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
      "  -0.27575966]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
      "   1.17073215]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
      "  -0.87137393]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "print('X_scaled:\\n', X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2702e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d08266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa927f7",
   "metadata": {},
   "source": [
    "We'll be using the other columsn to predict feature 9: Diabetes diagnoses (0, 1) where 0 = No, 1 = Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3e0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, input_dim=8, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab68ac9",
   "metadata": {},
   "source": [
    "## Compiling Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41516ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e97a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "11/11 [==============================] - 1s 16ms/step - loss: 0.7065 - accuracy: 0.6667 - val_loss: 0.7098 - val_accuracy: 0.5882\n",
      "Epoch 2/150\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.6765 - val_loss: 0.6985 - val_accuracy: 0.5882\n",
      "Epoch 3/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.6765 - val_loss: 0.6881 - val_accuracy: 0.5882\n",
      "Epoch 4/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.6667 - val_loss: 0.6787 - val_accuracy: 0.5882\n",
      "Epoch 5/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6667 - val_loss: 0.6718 - val_accuracy: 0.5882\n",
      "Epoch 6/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6765 - val_loss: 0.6645 - val_accuracy: 0.5882\n",
      "Epoch 7/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6279 - accuracy: 0.6765 - val_loss: 0.6575 - val_accuracy: 0.5882\n",
      "Epoch 8/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6188 - accuracy: 0.6765 - val_loss: 0.6496 - val_accuracy: 0.5882\n",
      "Epoch 9/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6863 - val_loss: 0.6424 - val_accuracy: 0.6078\n",
      "Epoch 10/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6863 - val_loss: 0.6358 - val_accuracy: 0.6078\n",
      "Epoch 11/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5928 - accuracy: 0.6863 - val_loss: 0.6305 - val_accuracy: 0.6275\n",
      "Epoch 12/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5863 - accuracy: 0.6961 - val_loss: 0.6255 - val_accuracy: 0.6275\n",
      "Epoch 13/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6961 - val_loss: 0.6206 - val_accuracy: 0.6078\n",
      "Epoch 14/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7059 - val_loss: 0.6132 - val_accuracy: 0.6078\n",
      "Epoch 15/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5655 - accuracy: 0.7059 - val_loss: 0.6074 - val_accuracy: 0.6078\n",
      "Epoch 16/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7157 - val_loss: 0.6020 - val_accuracy: 0.5882\n",
      "Epoch 17/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7157 - val_loss: 0.5975 - val_accuracy: 0.5686\n",
      "Epoch 18/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.7157 - val_loss: 0.5929 - val_accuracy: 0.6078\n",
      "Epoch 19/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7157 - val_loss: 0.5868 - val_accuracy: 0.6078\n",
      "Epoch 20/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7255 - val_loss: 0.5813 - val_accuracy: 0.6275\n",
      "Epoch 21/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7255 - val_loss: 0.5760 - val_accuracy: 0.6275\n",
      "Epoch 22/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7353 - val_loss: 0.5707 - val_accuracy: 0.6471\n",
      "Epoch 23/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7451 - val_loss: 0.5671 - val_accuracy: 0.6471\n",
      "Epoch 24/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7451 - val_loss: 0.5643 - val_accuracy: 0.6471\n",
      "Epoch 25/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7647 - val_loss: 0.5588 - val_accuracy: 0.6471\n",
      "Epoch 26/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7647 - val_loss: 0.5550 - val_accuracy: 0.6863\n",
      "Epoch 27/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7647 - val_loss: 0.5515 - val_accuracy: 0.6863\n",
      "Epoch 28/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7549 - val_loss: 0.5488 - val_accuracy: 0.6863\n",
      "Epoch 29/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7549 - val_loss: 0.5463 - val_accuracy: 0.6863\n",
      "Epoch 30/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7549 - val_loss: 0.5426 - val_accuracy: 0.6863\n",
      "Epoch 31/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7647 - val_loss: 0.5412 - val_accuracy: 0.6863\n",
      "Epoch 32/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7745 - val_loss: 0.5387 - val_accuracy: 0.6863\n",
      "Epoch 33/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7745 - val_loss: 0.5385 - val_accuracy: 0.6863\n",
      "Epoch 34/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7843 - val_loss: 0.5382 - val_accuracy: 0.6863\n",
      "Epoch 35/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7843 - val_loss: 0.5355 - val_accuracy: 0.6863\n",
      "Epoch 36/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8039 - val_loss: 0.5349 - val_accuracy: 0.6863\n",
      "Epoch 37/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.8137 - val_loss: 0.5344 - val_accuracy: 0.7059\n",
      "Epoch 38/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.8137 - val_loss: 0.5340 - val_accuracy: 0.7059\n",
      "Epoch 39/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.8137 - val_loss: 0.5328 - val_accuracy: 0.7059\n",
      "Epoch 40/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8235 - val_loss: 0.5328 - val_accuracy: 0.7059\n",
      "Epoch 41/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.5341 - val_accuracy: 0.7059\n",
      "Epoch 42/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8431 - val_loss: 0.5347 - val_accuracy: 0.7059\n",
      "Epoch 43/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8431 - val_loss: 0.5345 - val_accuracy: 0.7059\n",
      "Epoch 44/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8431 - val_loss: 0.5348 - val_accuracy: 0.7059\n",
      "Epoch 45/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8431 - val_loss: 0.5366 - val_accuracy: 0.7059\n",
      "Epoch 46/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8431 - val_loss: 0.5377 - val_accuracy: 0.7059\n",
      "Epoch 47/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8431 - val_loss: 0.5390 - val_accuracy: 0.7059\n",
      "Epoch 48/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8431 - val_loss: 0.5398 - val_accuracy: 0.7059\n",
      "Epoch 49/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.8431 - val_loss: 0.5402 - val_accuracy: 0.7059\n",
      "Epoch 50/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8333 - val_loss: 0.5412 - val_accuracy: 0.7059\n",
      "Epoch 51/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8333 - val_loss: 0.5374 - val_accuracy: 0.7059\n",
      "Epoch 52/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8333 - val_loss: 0.5396 - val_accuracy: 0.7059\n",
      "Epoch 53/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3875 - accuracy: 0.8333 - val_loss: 0.5416 - val_accuracy: 0.7059\n",
      "Epoch 54/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3852 - accuracy: 0.8333 - val_loss: 0.5429 - val_accuracy: 0.7059\n",
      "Epoch 55/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8333 - val_loss: 0.5451 - val_accuracy: 0.7059\n",
      "Epoch 56/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8333 - val_loss: 0.5458 - val_accuracy: 0.7059\n",
      "Epoch 57/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3786 - accuracy: 0.8333 - val_loss: 0.5467 - val_accuracy: 0.7059\n",
      "Epoch 58/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3759 - accuracy: 0.8431 - val_loss: 0.5479 - val_accuracy: 0.7059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3741 - accuracy: 0.8431 - val_loss: 0.5497 - val_accuracy: 0.7059\n",
      "Epoch 60/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8431 - val_loss: 0.5506 - val_accuracy: 0.7059\n",
      "Epoch 61/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8431 - val_loss: 0.5532 - val_accuracy: 0.7059\n",
      "Epoch 62/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8431 - val_loss: 0.5556 - val_accuracy: 0.7059\n",
      "Epoch 63/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8431 - val_loss: 0.5589 - val_accuracy: 0.7059\n",
      "Epoch 64/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8431 - val_loss: 0.5601 - val_accuracy: 0.7059\n",
      "Epoch 65/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3608 - accuracy: 0.8431 - val_loss: 0.5582 - val_accuracy: 0.7059\n",
      "Epoch 66/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.8431 - val_loss: 0.5580 - val_accuracy: 0.7059\n",
      "Epoch 67/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8431 - val_loss: 0.5601 - val_accuracy: 0.7059\n",
      "Epoch 68/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8529 - val_loss: 0.5620 - val_accuracy: 0.7059\n",
      "Epoch 69/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3541 - accuracy: 0.8627 - val_loss: 0.5637 - val_accuracy: 0.6863\n",
      "Epoch 70/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8627 - val_loss: 0.5657 - val_accuracy: 0.7059\n",
      "Epoch 71/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8529 - val_loss: 0.5665 - val_accuracy: 0.7059\n",
      "Epoch 72/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8529 - val_loss: 0.5682 - val_accuracy: 0.7059\n",
      "Epoch 73/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8627 - val_loss: 0.5671 - val_accuracy: 0.6863\n",
      "Epoch 74/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8627 - val_loss: 0.5689 - val_accuracy: 0.7059\n",
      "Epoch 75/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8627 - val_loss: 0.5707 - val_accuracy: 0.7059\n",
      "Epoch 76/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8627 - val_loss: 0.5735 - val_accuracy: 0.7059\n",
      "Epoch 77/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8627 - val_loss: 0.5750 - val_accuracy: 0.6863\n",
      "Epoch 78/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8627 - val_loss: 0.5760 - val_accuracy: 0.6863\n",
      "Epoch 79/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8627 - val_loss: 0.5769 - val_accuracy: 0.7059\n",
      "Epoch 80/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8627 - val_loss: 0.5764 - val_accuracy: 0.7059\n",
      "Epoch 81/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8627 - val_loss: 0.5764 - val_accuracy: 0.7255\n",
      "Epoch 82/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8627 - val_loss: 0.5776 - val_accuracy: 0.7059\n",
      "Epoch 83/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8627 - val_loss: 0.5785 - val_accuracy: 0.7059\n",
      "Epoch 84/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3328 - accuracy: 0.8627 - val_loss: 0.5789 - val_accuracy: 0.7059\n",
      "Epoch 85/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8529 - val_loss: 0.5791 - val_accuracy: 0.7059\n",
      "Epoch 86/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8529 - val_loss: 0.5811 - val_accuracy: 0.7255\n",
      "Epoch 87/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8529 - val_loss: 0.5827 - val_accuracy: 0.7059\n",
      "Epoch 88/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8529 - val_loss: 0.5842 - val_accuracy: 0.7255\n",
      "Epoch 89/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8529 - val_loss: 0.5852 - val_accuracy: 0.7255\n",
      "Epoch 90/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8529 - val_loss: 0.5874 - val_accuracy: 0.7255\n",
      "Epoch 91/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8529 - val_loss: 0.5900 - val_accuracy: 0.7255\n",
      "Epoch 92/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8529 - val_loss: 0.5923 - val_accuracy: 0.7255\n",
      "Epoch 93/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8529 - val_loss: 0.5928 - val_accuracy: 0.7255\n",
      "Epoch 94/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8529 - val_loss: 0.5940 - val_accuracy: 0.7255\n",
      "Epoch 95/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8529 - val_loss: 0.5965 - val_accuracy: 0.7255\n",
      "Epoch 96/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8529 - val_loss: 0.5974 - val_accuracy: 0.7255\n",
      "Epoch 97/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3152 - accuracy: 0.8529 - val_loss: 0.5969 - val_accuracy: 0.7059\n",
      "Epoch 98/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3146 - accuracy: 0.8529 - val_loss: 0.5970 - val_accuracy: 0.7059\n",
      "Epoch 99/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8529 - val_loss: 0.5980 - val_accuracy: 0.7059\n",
      "Epoch 100/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8529 - val_loss: 0.6001 - val_accuracy: 0.7059\n",
      "Epoch 101/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8529 - val_loss: 0.6046 - val_accuracy: 0.7059\n",
      "Epoch 102/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8627 - val_loss: 0.6069 - val_accuracy: 0.7059\n",
      "Epoch 103/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8627 - val_loss: 0.6087 - val_accuracy: 0.7059\n",
      "Epoch 104/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8529 - val_loss: 0.6105 - val_accuracy: 0.7059\n",
      "Epoch 105/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8529 - val_loss: 0.6116 - val_accuracy: 0.7059\n",
      "Epoch 106/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8529 - val_loss: 0.6149 - val_accuracy: 0.7059\n",
      "Epoch 107/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8529 - val_loss: 0.6191 - val_accuracy: 0.7059\n",
      "Epoch 108/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8529 - val_loss: 0.6216 - val_accuracy: 0.7059\n",
      "Epoch 109/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8529 - val_loss: 0.6236 - val_accuracy: 0.7059\n",
      "Epoch 110/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8529 - val_loss: 0.6222 - val_accuracy: 0.7059\n",
      "Epoch 111/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8529 - val_loss: 0.6244 - val_accuracy: 0.7059\n",
      "Epoch 112/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8529 - val_loss: 0.6270 - val_accuracy: 0.7059\n",
      "Epoch 113/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8529 - val_loss: 0.6273 - val_accuracy: 0.6863\n",
      "Epoch 114/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8529 - val_loss: 0.6276 - val_accuracy: 0.6863\n",
      "Epoch 115/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8627 - val_loss: 0.6286 - val_accuracy: 0.6863\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8627 - val_loss: 0.6302 - val_accuracy: 0.6863\n",
      "Epoch 117/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8627 - val_loss: 0.6337 - val_accuracy: 0.6863\n",
      "Epoch 118/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8627 - val_loss: 0.6291 - val_accuracy: 0.7059\n",
      "Epoch 119/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8627 - val_loss: 0.6284 - val_accuracy: 0.7059\n",
      "Epoch 120/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8627 - val_loss: 0.6328 - val_accuracy: 0.7059\n",
      "Epoch 121/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8627 - val_loss: 0.6364 - val_accuracy: 0.7059\n",
      "Epoch 122/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8627 - val_loss: 0.6388 - val_accuracy: 0.7059\n",
      "Epoch 123/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8627 - val_loss: 0.6408 - val_accuracy: 0.7059\n",
      "Epoch 124/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8725 - val_loss: 0.6430 - val_accuracy: 0.7059\n",
      "Epoch 125/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8824 - val_loss: 0.6458 - val_accuracy: 0.7059\n",
      "Epoch 126/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8725 - val_loss: 0.6468 - val_accuracy: 0.7059\n",
      "Epoch 127/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2723 - accuracy: 0.8725 - val_loss: 0.6490 - val_accuracy: 0.7059\n",
      "Epoch 128/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.8725 - val_loss: 0.6513 - val_accuracy: 0.7059\n",
      "Epoch 129/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8725 - val_loss: 0.6526 - val_accuracy: 0.7059\n",
      "Epoch 130/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8922 - val_loss: 0.6542 - val_accuracy: 0.7059\n",
      "Epoch 131/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8922 - val_loss: 0.6575 - val_accuracy: 0.7059\n",
      "Epoch 132/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.9020 - val_loss: 0.6596 - val_accuracy: 0.7059\n",
      "Epoch 133/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9020 - val_loss: 0.6658 - val_accuracy: 0.7059\n",
      "Epoch 134/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.9020 - val_loss: 0.6683 - val_accuracy: 0.7059\n",
      "Epoch 135/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8922 - val_loss: 0.6695 - val_accuracy: 0.7059\n",
      "Epoch 136/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2596 - accuracy: 0.8922 - val_loss: 0.6730 - val_accuracy: 0.7059\n",
      "Epoch 137/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9020 - val_loss: 0.6728 - val_accuracy: 0.7059\n",
      "Epoch 138/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.9020 - val_loss: 0.6735 - val_accuracy: 0.7059\n",
      "Epoch 139/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9020 - val_loss: 0.6725 - val_accuracy: 0.7059\n",
      "Epoch 140/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2523 - accuracy: 0.9020 - val_loss: 0.6750 - val_accuracy: 0.7059\n",
      "Epoch 141/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.9020 - val_loss: 0.6783 - val_accuracy: 0.7059\n",
      "Epoch 142/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.9020 - val_loss: 0.6763 - val_accuracy: 0.7059\n",
      "Epoch 143/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9020 - val_loss: 0.6790 - val_accuracy: 0.7059\n",
      "Epoch 144/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9020 - val_loss: 0.6826 - val_accuracy: 0.7059\n",
      "Epoch 145/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2466 - accuracy: 0.9020 - val_loss: 0.6849 - val_accuracy: 0.7059\n",
      "Epoch 146/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.9020 - val_loss: 0.6878 - val_accuracy: 0.7059\n",
      "Epoch 147/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9020 - val_loss: 0.6903 - val_accuracy: 0.7059\n",
      "Epoch 148/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2413 - accuracy: 0.9020 - val_loss: 0.6896 - val_accuracy: 0.7059\n",
      "Epoch 149/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9020 - val_loss: 0.6920 - val_accuracy: 0.7059\n",
      "Epoch 150/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.9020 - val_loss: 0.6965 - val_accuracy: 0.7059\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(X_train, y_train, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e603378a",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d40ae35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8301\n",
      "83.0065369606018\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20c717",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "740b1690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step\n",
      "[0.6399472601593604, -0.7165334717264664, -0.5741277459136239, 0.7818138030884986, 0.9568596530309466, 0.2547804694892914, -0.12647140206047627, 0.8303811324799334] 1 1\n",
      "[-0.5479185907225461, -0.2783734371474431, 0.30473400231574344, 0.7190857419965673, -0.6928905722954675, 0.4705431865971717, -0.9781448690748651, -1.0415494364835023] 0 0\n",
      "[-0.5479185907225461, -0.4035620184557355, -0.2639412465385531, -1.2882122129452358, -0.6928905722954675, -0.1513611156549531, -0.9479436823013052, -1.0415494364835023] 0 1\n",
      "[1.2338801856003137, -0.4348591637828086, 0.5632227517949692, -1.2882122129452358, -0.6928905722954675, -0.938260436871927, 1.160099154493175, 0.06459135426761875] 1 0\n",
      "[0.9369137228798371, 0.4727580507023112, 1.0802002507534205, -1.2882122129452358, -0.6928905722954675, -0.26558843647677216, -0.7908975110787937, 1.4259954044228447] 0 1\n",
      "[0.6399472601593604, -0.560047745091101, 0.149640752628208, 0.7190857419965673, 0.9568596530309466, 0.7243816773123246, -0.446603981860211, 1.8514341700963528] 0 0\n",
      "[-0.8448850534430228, -1.56155639555744, -1.0911052448720753, -0.1591071132904716, -0.03299048216490188, -1.4713212673737484, -0.449624100537567, -0.9564616833488008] 0 1\n",
      "[-1.1418515161634994, -0.12188771051207764, -3.572597239872642, -1.2882122129452358, -0.6928905722954675, 0.22939662041777578, 1.38962817397223, 0.915468885614635] 1 0\n",
      "[0.04601433471840714, 1.036106666589627, 0.149640752628208, 0.5309015587207732, 0.4011543139736281, -0.08790149297616488, -0.40432232037722715, 0.31985461367172363] 0 1\n",
      "[0.34298079743888377, 0.8170266493001153, 0.45982725200327884, -1.2882122129452358, -0.6928905722954675, 0.21670469588201885, -0.7667365616599457, 2.702311701443369] 1 1\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "for i in range(10):\n",
    "    print(X_test[i].tolist(), predictions[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e80f8273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 867us/step\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['0' '1'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:781\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mFind the union of two arrays.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munion1d(y_true, y_pred)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions provided by the classifier coincides with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_values) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    127\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['0' '1'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7adfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
