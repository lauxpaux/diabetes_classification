{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24315f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f11b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "from numpy import loadtxt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import rcParams\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca142d7",
   "metadata": {},
   "source": [
    "### The data columns are:\n",
    "\n",
    "1) Pregnancy\n",
    "2) Glucose\n",
    "3) Blood Pressure\n",
    "4) SkinThickness\n",
    "5) Insulin\n",
    "6) BMI\n",
    "7) DiabetesPedigreeFunction\n",
    "8) Age\n",
    "9) Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfefe0",
   "metadata": {},
   "source": [
    "We will be prediction column (9), whether the person has diabetes(1) or not(0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb54dc3",
   "metadata": {},
   "source": [
    "## Loading dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37621b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/diabetes.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1436d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.34</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1   2   3    4     5      6   7  8\n",
       "1     6  148  72  35    0  33.6  0.627  50  1\n",
       "2     1   85  66  29    0  26.6  0.351  31  0\n",
       "3     8  183  64   0    0  23.3  0.672  32  1\n",
       "4     1   89  66  23   94  28.1  0.167  21  0\n",
       "5     0  137  40  35  168  43.1  2.288  33  1\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "764  10  101  76  48  180  32.9  0.171  63  0\n",
       "765   2  122  70  27    0  36.8   0.34  27  0\n",
       "766   5  121  72  23  112  26.2  0.245  30  0\n",
       "767   1  126  60   0    0  30.1  0.349  47  1\n",
       "768   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(0, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ca96d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['6', '148', '72', ..., '0.627', '50', '1'],\n",
       "       ['1', '85', '66', ..., '0.351', '31', '0'],\n",
       "       ['8', '183', '64', ..., '0.672', '32', '1'],\n",
       "       ...,\n",
       "       ['5', '121', '72', ..., '0.245', '30', '0'],\n",
       "       ['1', '126', '60', ..., '0.349', '47', '1'],\n",
       "       ['1', '93', '70', ..., '0.315', '23', '0']], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.to_numpy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95cf6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0:8]\n",
    "y = data[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f146960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3ea885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled:\n",
      " [[ 0.63994726  0.84832379  0.14964075 ...  0.20401277  0.46849198\n",
      "   1.4259954 ]\n",
      " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
      "  -0.19067191]\n",
      " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325546  0.60439732\n",
      "  -0.10558415]\n",
      " ...\n",
      " [ 0.3429808   0.00330087  0.14964075 ... -0.73518964 -0.68519336\n",
      "  -0.27575966]\n",
      " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
      "   1.17073215]\n",
      " [-0.84488505 -0.8730192   0.04624525 ... -0.20212881 -0.47378505\n",
      "  -0.87137393]]\n"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)\n",
    "print('X_scaled:\\n', X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566d1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c193c39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f800a436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116e8e0",
   "metadata": {},
   "source": [
    "We'll be using the other columsn to predict feature 9: Diabetes diagnoses (0, 1) where 0 = No, 1 = Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3eb655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, input_dim=8, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b853c02",
   "metadata": {},
   "source": [
    "## Compiling Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133683fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b052b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "11/11 [==============================] - 1s 17ms/step - loss: 0.7436 - accuracy: 0.5588 - val_loss: 0.7383 - val_accuracy: 0.5098\n",
      "Epoch 2/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.5784 - val_loss: 0.7246 - val_accuracy: 0.5294\n",
      "Epoch 3/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.7123 - accuracy: 0.6078 - val_loss: 0.7133 - val_accuracy: 0.5490\n",
      "Epoch 4/150\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.7010 - accuracy: 0.6373 - val_loss: 0.7039 - val_accuracy: 0.5490\n",
      "Epoch 5/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.6373 - val_loss: 0.6965 - val_accuracy: 0.5686\n",
      "Epoch 6/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.6373 - val_loss: 0.6899 - val_accuracy: 0.5882\n",
      "Epoch 7/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.6471 - val_loss: 0.6840 - val_accuracy: 0.5882\n",
      "Epoch 8/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.6569 - val_loss: 0.6782 - val_accuracy: 0.6078\n",
      "Epoch 9/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.6667 - val_loss: 0.6729 - val_accuracy: 0.6078\n",
      "Epoch 10/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.6569 - val_loss: 0.6678 - val_accuracy: 0.6078\n",
      "Epoch 11/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.6471 - val_loss: 0.6629 - val_accuracy: 0.6078\n",
      "Epoch 12/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6471 - val_loss: 0.6583 - val_accuracy: 0.6078\n",
      "Epoch 13/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6569 - val_loss: 0.6539 - val_accuracy: 0.6078\n",
      "Epoch 14/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6373 - val_loss: 0.6496 - val_accuracy: 0.6275\n",
      "Epoch 15/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6289 - accuracy: 0.6275 - val_loss: 0.6454 - val_accuracy: 0.6078\n",
      "Epoch 16/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.6275 - val_loss: 0.6406 - val_accuracy: 0.6275\n",
      "Epoch 17/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.6275 - val_loss: 0.6365 - val_accuracy: 0.5882\n",
      "Epoch 18/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6128 - accuracy: 0.6275 - val_loss: 0.6329 - val_accuracy: 0.6078\n",
      "Epoch 19/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6082 - accuracy: 0.6471 - val_loss: 0.6295 - val_accuracy: 0.6078\n",
      "Epoch 20/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6029 - accuracy: 0.6569 - val_loss: 0.6261 - val_accuracy: 0.6078\n",
      "Epoch 21/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5982 - accuracy: 0.6569 - val_loss: 0.6224 - val_accuracy: 0.6078\n",
      "Epoch 22/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.6569 - val_loss: 0.6192 - val_accuracy: 0.6078\n",
      "Epoch 23/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5879 - accuracy: 0.6569 - val_loss: 0.6162 - val_accuracy: 0.6078\n",
      "Epoch 24/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5831 - accuracy: 0.6569 - val_loss: 0.6136 - val_accuracy: 0.6078\n",
      "Epoch 25/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5775 - accuracy: 0.6765 - val_loss: 0.6098 - val_accuracy: 0.6275\n",
      "Epoch 26/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.6667 - val_loss: 0.6061 - val_accuracy: 0.6275\n",
      "Epoch 27/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.6863 - val_loss: 0.6035 - val_accuracy: 0.6275\n",
      "Epoch 28/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5627 - accuracy: 0.6863 - val_loss: 0.6003 - val_accuracy: 0.6275\n",
      "Epoch 29/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.6961 - val_loss: 0.5980 - val_accuracy: 0.6275\n",
      "Epoch 30/150\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.6961 - val_loss: 0.5952 - val_accuracy: 0.6275\n",
      "Epoch 31/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5475 - accuracy: 0.7255 - val_loss: 0.5923 - val_accuracy: 0.6275\n",
      "Epoch 32/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7255 - val_loss: 0.5899 - val_accuracy: 0.6471\n",
      "Epoch 33/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7255 - val_loss: 0.5873 - val_accuracy: 0.6667\n",
      "Epoch 34/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7451 - val_loss: 0.5849 - val_accuracy: 0.6471\n",
      "Epoch 35/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7451 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5239 - accuracy: 0.7353 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7451 - val_loss: 0.5794 - val_accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7451 - val_loss: 0.5756 - val_accuracy: 0.7059\n",
      "Epoch 39/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7549 - val_loss: 0.5733 - val_accuracy: 0.7451\n",
      "Epoch 40/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7549 - val_loss: 0.5706 - val_accuracy: 0.7451\n",
      "Epoch 41/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7451 - val_loss: 0.5677 - val_accuracy: 0.7647\n",
      "Epoch 42/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7745 - val_loss: 0.5650 - val_accuracy: 0.7647\n",
      "Epoch 43/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.7745 - val_loss: 0.5621 - val_accuracy: 0.7647\n",
      "Epoch 44/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7745 - val_loss: 0.5615 - val_accuracy: 0.7647\n",
      "Epoch 45/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7843 - val_loss: 0.5593 - val_accuracy: 0.7843\n",
      "Epoch 46/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7843 - val_loss: 0.5586 - val_accuracy: 0.7647\n",
      "Epoch 47/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7843 - val_loss: 0.5588 - val_accuracy: 0.7843\n",
      "Epoch 48/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7941 - val_loss: 0.5586 - val_accuracy: 0.7843\n",
      "Epoch 49/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7941 - val_loss: 0.5589 - val_accuracy: 0.7647\n",
      "Epoch 50/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7941 - val_loss: 0.5580 - val_accuracy: 0.7647\n",
      "Epoch 51/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8039 - val_loss: 0.5568 - val_accuracy: 0.7647\n",
      "Epoch 52/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8137 - val_loss: 0.5566 - val_accuracy: 0.7647\n",
      "Epoch 53/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8137 - val_loss: 0.5558 - val_accuracy: 0.7647\n",
      "Epoch 54/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.8137 - val_loss: 0.5567 - val_accuracy: 0.7647\n",
      "Epoch 55/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8137 - val_loss: 0.5578 - val_accuracy: 0.7451\n",
      "Epoch 56/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.8137 - val_loss: 0.5572 - val_accuracy: 0.7647\n",
      "Epoch 57/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8137 - val_loss: 0.5576 - val_accuracy: 0.7647\n",
      "Epoch 58/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8137 - val_loss: 0.5571 - val_accuracy: 0.7451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8137 - val_loss: 0.5555 - val_accuracy: 0.7451\n",
      "Epoch 60/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8137 - val_loss: 0.5560 - val_accuracy: 0.7451\n",
      "Epoch 61/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8137 - val_loss: 0.5577 - val_accuracy: 0.7451\n",
      "Epoch 62/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8137 - val_loss: 0.5606 - val_accuracy: 0.7451\n",
      "Epoch 63/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.4012 - accuracy: 0.8137 - val_loss: 0.5626 - val_accuracy: 0.7451\n",
      "Epoch 64/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3985 - accuracy: 0.8137 - val_loss: 0.5616 - val_accuracy: 0.7451\n",
      "Epoch 65/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8235 - val_loss: 0.5576 - val_accuracy: 0.7451\n",
      "Epoch 66/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3942 - accuracy: 0.8235 - val_loss: 0.5553 - val_accuracy: 0.7451\n",
      "Epoch 67/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3915 - accuracy: 0.8137 - val_loss: 0.5561 - val_accuracy: 0.7255\n",
      "Epoch 68/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.8235 - val_loss: 0.5603 - val_accuracy: 0.7451\n",
      "Epoch 69/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8235 - val_loss: 0.5615 - val_accuracy: 0.7451\n",
      "Epoch 70/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8235 - val_loss: 0.5616 - val_accuracy: 0.7451\n",
      "Epoch 71/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3788 - accuracy: 0.8235 - val_loss: 0.5610 - val_accuracy: 0.7451\n",
      "Epoch 72/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3771 - accuracy: 0.8333 - val_loss: 0.5600 - val_accuracy: 0.7451\n",
      "Epoch 73/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8333 - val_loss: 0.5601 - val_accuracy: 0.7451\n",
      "Epoch 74/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3713 - accuracy: 0.8333 - val_loss: 0.5609 - val_accuracy: 0.7451\n",
      "Epoch 75/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8235 - val_loss: 0.5639 - val_accuracy: 0.7451\n",
      "Epoch 76/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8137 - val_loss: 0.5658 - val_accuracy: 0.7451\n",
      "Epoch 77/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3648 - accuracy: 0.8137 - val_loss: 0.5662 - val_accuracy: 0.7451\n",
      "Epoch 78/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8137 - val_loss: 0.5692 - val_accuracy: 0.7451\n",
      "Epoch 79/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8137 - val_loss: 0.5678 - val_accuracy: 0.7451\n",
      "Epoch 80/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.8137 - val_loss: 0.5699 - val_accuracy: 0.7451\n",
      "Epoch 81/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8137 - val_loss: 0.5726 - val_accuracy: 0.7451\n",
      "Epoch 82/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8333 - val_loss: 0.5769 - val_accuracy: 0.7451\n",
      "Epoch 83/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8333 - val_loss: 0.5751 - val_accuracy: 0.7451\n",
      "Epoch 84/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8235 - val_loss: 0.5756 - val_accuracy: 0.7451\n",
      "Epoch 85/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3474 - accuracy: 0.8333 - val_loss: 0.5772 - val_accuracy: 0.7451\n",
      "Epoch 86/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8235 - val_loss: 0.5785 - val_accuracy: 0.7451\n",
      "Epoch 87/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8235 - val_loss: 0.5796 - val_accuracy: 0.7451\n",
      "Epoch 88/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8235 - val_loss: 0.5780 - val_accuracy: 0.7451\n",
      "Epoch 89/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8235 - val_loss: 0.5807 - val_accuracy: 0.7451\n",
      "Epoch 90/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8235 - val_loss: 0.5845 - val_accuracy: 0.7451\n",
      "Epoch 91/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8235 - val_loss: 0.5859 - val_accuracy: 0.7255\n",
      "Epoch 92/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8235 - val_loss: 0.5881 - val_accuracy: 0.7255\n",
      "Epoch 93/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8235 - val_loss: 0.5903 - val_accuracy: 0.7255\n",
      "Epoch 94/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8431 - val_loss: 0.5898 - val_accuracy: 0.7255\n",
      "Epoch 95/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8529 - val_loss: 0.5906 - val_accuracy: 0.7255\n",
      "Epoch 96/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3277 - accuracy: 0.8529 - val_loss: 0.5945 - val_accuracy: 0.7255\n",
      "Epoch 97/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3261 - accuracy: 0.8529 - val_loss: 0.5984 - val_accuracy: 0.7451\n",
      "Epoch 98/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3227 - accuracy: 0.8529 - val_loss: 0.6018 - val_accuracy: 0.7647\n",
      "Epoch 99/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.8431 - val_loss: 0.6036 - val_accuracy: 0.7647\n",
      "Epoch 100/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8431 - val_loss: 0.6037 - val_accuracy: 0.7647\n",
      "Epoch 101/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3181 - accuracy: 0.8529 - val_loss: 0.6058 - val_accuracy: 0.7647\n",
      "Epoch 102/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8529 - val_loss: 0.6085 - val_accuracy: 0.7647\n",
      "Epoch 103/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.8529 - val_loss: 0.6107 - val_accuracy: 0.7647\n",
      "Epoch 104/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3134 - accuracy: 0.8529 - val_loss: 0.6160 - val_accuracy: 0.7647\n",
      "Epoch 105/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8529 - val_loss: 0.6141 - val_accuracy: 0.7647\n",
      "Epoch 106/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8627 - val_loss: 0.6099 - val_accuracy: 0.7647\n",
      "Epoch 107/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3087 - accuracy: 0.8529 - val_loss: 0.6033 - val_accuracy: 0.7451\n",
      "Epoch 108/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8529 - val_loss: 0.6034 - val_accuracy: 0.7451\n",
      "Epoch 109/150\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8529 - val_loss: 0.6044 - val_accuracy: 0.7451\n",
      "Epoch 110/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.3033 - accuracy: 0.8725 - val_loss: 0.6057 - val_accuracy: 0.7451\n",
      "Epoch 111/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8725 - val_loss: 0.6066 - val_accuracy: 0.7451\n",
      "Epoch 112/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.3001 - accuracy: 0.8824 - val_loss: 0.6093 - val_accuracy: 0.7451\n",
      "Epoch 113/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8922 - val_loss: 0.6108 - val_accuracy: 0.7451\n",
      "Epoch 114/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8824 - val_loss: 0.6158 - val_accuracy: 0.7451\n",
      "Epoch 115/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8824 - val_loss: 0.6189 - val_accuracy: 0.7451\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2939 - accuracy: 0.8824 - val_loss: 0.6158 - val_accuracy: 0.7451\n",
      "Epoch 117/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8922 - val_loss: 0.6153 - val_accuracy: 0.7451\n",
      "Epoch 118/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8922 - val_loss: 0.6189 - val_accuracy: 0.7451\n",
      "Epoch 119/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8922 - val_loss: 0.6211 - val_accuracy: 0.7451\n",
      "Epoch 120/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8922 - val_loss: 0.6199 - val_accuracy: 0.7451\n",
      "Epoch 121/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.8922 - val_loss: 0.6221 - val_accuracy: 0.7451\n",
      "Epoch 122/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8922 - val_loss: 0.6234 - val_accuracy: 0.7451\n",
      "Epoch 123/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8922 - val_loss: 0.6234 - val_accuracy: 0.7451\n",
      "Epoch 124/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8922 - val_loss: 0.6273 - val_accuracy: 0.7451\n",
      "Epoch 125/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8824 - val_loss: 0.6300 - val_accuracy: 0.7647\n",
      "Epoch 126/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2799 - accuracy: 0.8922 - val_loss: 0.6330 - val_accuracy: 0.7647\n",
      "Epoch 127/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8922 - val_loss: 0.6340 - val_accuracy: 0.7647\n",
      "Epoch 128/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8922 - val_loss: 0.6331 - val_accuracy: 0.7451\n",
      "Epoch 129/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8824 - val_loss: 0.6347 - val_accuracy: 0.7451\n",
      "Epoch 130/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.8824 - val_loss: 0.6391 - val_accuracy: 0.7451\n",
      "Epoch 131/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8824 - val_loss: 0.6402 - val_accuracy: 0.7451\n",
      "Epoch 132/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8725 - val_loss: 0.6434 - val_accuracy: 0.7451\n",
      "Epoch 133/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8824 - val_loss: 0.6491 - val_accuracy: 0.7451\n",
      "Epoch 134/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.8922 - val_loss: 0.6464 - val_accuracy: 0.7451\n",
      "Epoch 135/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2656 - accuracy: 0.9020 - val_loss: 0.6438 - val_accuracy: 0.7451\n",
      "Epoch 136/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.9020 - val_loss: 0.6450 - val_accuracy: 0.7451\n",
      "Epoch 137/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9020 - val_loss: 0.6501 - val_accuracy: 0.7451\n",
      "Epoch 138/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2633 - accuracy: 0.9020 - val_loss: 0.6455 - val_accuracy: 0.7451\n",
      "Epoch 139/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8824 - val_loss: 0.6489 - val_accuracy: 0.7451\n",
      "Epoch 140/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2593 - accuracy: 0.9020 - val_loss: 0.6509 - val_accuracy: 0.7451\n",
      "Epoch 141/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.9020 - val_loss: 0.6573 - val_accuracy: 0.7451\n",
      "Epoch 142/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9020 - val_loss: 0.6595 - val_accuracy: 0.7451\n",
      "Epoch 143/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9020 - val_loss: 0.6613 - val_accuracy: 0.7451\n",
      "Epoch 144/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9020 - val_loss: 0.6661 - val_accuracy: 0.7451\n",
      "Epoch 145/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9020 - val_loss: 0.6715 - val_accuracy: 0.7451\n",
      "Epoch 146/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8922 - val_loss: 0.6723 - val_accuracy: 0.7451\n",
      "Epoch 147/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2504 - accuracy: 0.8922 - val_loss: 0.6714 - val_accuracy: 0.7451\n",
      "Epoch 148/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9020 - val_loss: 0.6722 - val_accuracy: 0.7451\n",
      "Epoch 149/150\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9118 - val_loss: 0.6742 - val_accuracy: 0.7451\n",
      "Epoch 150/150\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.9020 - val_loss: 0.6784 - val_accuracy: 0.7451\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(X_train, y_train, validation_split=0.33, epochs=150, batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c6569",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f892a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8562\n",
      "85.62091588973999\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a0f3ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "print(type(accuracy))\n",
    "print(type(_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d45f676",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b14540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 850us/step\n",
      "[0.6399472601593604, -0.7165334717264664, -0.5741277459136239, 0.7818138030884986, 0.9568596530309466, 0.2547804694892914, -0.12647140206047627, 0.8303811324799334] 0 1\n",
      "[-0.5479185907225461, -0.2783734371474431, 0.30473400231574344, 0.7190857419965673, -0.6928905722954675, 0.4705431865971717, -0.9781448690748651, -1.0415494364835023] 0 0\n",
      "[-0.5479185907225461, -0.4035620184557355, -0.2639412465385531, -1.2882122129452358, -0.6928905722954675, -0.1513611156549531, -0.9479436823013052, -1.0415494364835023] 0 1\n",
      "[1.2338801856003137, -0.4348591637828086, 0.5632227517949692, -1.2882122129452358, -0.6928905722954675, -0.938260436871927, 1.160099154493175, 0.06459135426761875] 0 0\n",
      "[0.9369137228798371, 0.4727580507023112, 1.0802002507534205, -1.2882122129452358, -0.6928905722954675, -0.26558843647677216, -0.7908975110787937, 1.4259954044228447] 1 1\n",
      "[0.6399472601593604, -0.560047745091101, 0.149640752628208, 0.7190857419965673, 0.9568596530309466, 0.7243816773123246, -0.446603981860211, 1.8514341700963528] 0 0\n",
      "[-0.8448850534430228, -1.56155639555744, -1.0911052448720753, -0.1591071132904716, -0.03299048216490188, -1.4713212673737484, -0.449624100537567, -0.9564616833488008] 0 1\n",
      "[-1.1418515161634994, -0.12188771051207764, -3.572597239872642, -1.2882122129452358, -0.6928905722954675, 0.22939662041777578, 1.38962817397223, 0.915468885614635] 1 0\n",
      "[0.04601433471840714, 1.036106666589627, 0.149640752628208, 0.5309015587207732, 0.4011543139736281, -0.08790149297616488, -0.40432232037722715, 0.31985461367172363] 1 1\n",
      "[0.34298079743888377, 0.8170266493001153, 0.45982725200327884, -1.2882122129452358, -0.6928905722954675, 0.21670469588201885, -0.7667365616599457, 2.702311701443369] 1 1\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "for i in range(10):\n",
    "    print(X_test[i].tolist(), predictions[i], y[i])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "732f7cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d941ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cee5f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 919us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6012138 , 0.33926383],\n",
       "       [0.97549105, 0.03605298],\n",
       "       [0.92440337, 0.10895424],\n",
       "       ...,\n",
       "       [0.49479282, 0.48594034],\n",
       "       [0.89102083, 0.14259213],\n",
       "       [0.09416676, 0.89994365]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7dd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70580fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d75af291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af46c8d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=['0' '1'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:113\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munion1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:781\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03mFind the union of two arrays.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mar2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/diabetes_prediction/lib/python3.11/site-packages/sklearn/metrics/_classification.py:119\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    113\u001b[0m     unique_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munion1d(y_true, y_pred)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot y_true=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_true)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39munique(y_pred)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions provided by the classifier coincides with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe true labels.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_values) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    127\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=['0' '1'] and y_pred=[0 1]. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d153f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
